{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a3b469a7",
      "metadata": {
        "id": "a3b469a7"
      },
      "source": [
        "# üß† RAG Workshop Assignment - Meghana\n",
        "**Student ID:** 24156991  \n",
        "**Topic:** AI in Healthcare  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18500c77",
      "metadata": {
        "id": "18500c77"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# Import required libraries\n",
        "# -------------------------------------------------------------\n",
        "import pandas as pd\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad39b412",
      "metadata": {
        "id": "ad39b412"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# 1Ô∏è‚É£ Load Data from Excel\n",
        "# -------------------------------------------------------------\n",
        "file_path = \"AI_Medical_Diagnosis_Data.xlsx\"  # Uploaded dataset\n",
        "df = pd.read_excel(file_path, sheet_name=\"Data\")  # Load the 'Data' sheet\n",
        "\n",
        "# Convert rows into readable text for RAG processing\n",
        "data_texts = []\n",
        "for index, row in df.iterrows():\n",
        "    text = (\n",
        "        f\"Patient ID: {row['Patient ID']}, \"\n",
        "        f\"Age: {row['Age']}, \"\n",
        "        f\"Symptoms: {row['Symptoms']}, \"\n",
        "        f\"AI Diagnosis: {row['AI Diagnosis']}, \"\n",
        "        f\"Accuracy: {row['Accuracy (%)']}%\"\n",
        "    )\n",
        "    data_texts.append(text)\n",
        "\n",
        "# Combine all rows into one text block\n",
        "full_text = \"\\n\".join(data_texts)\n",
        "print(\"‚úÖ Excel data loaded and converted into text format.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88d7d7ba",
      "metadata": {
        "id": "88d7d7ba"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# 2Ô∏è‚É£ Text Chunking (Modified Parameters)\n",
        "# -------------------------------------------------------------\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1200,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \", \"\"]\n",
        ")\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "print(f\"‚úÖ Created {len(chunks)} text chunks for embedding.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f43da13c",
      "metadata": {
        "id": "f43da13c"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# 3Ô∏è‚É£ Embedding and Vectorstore\n",
        "# -------------------------------------------------------------\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_texts(chunks, embeddings)\n",
        "print(\"‚úÖ FAISS vectorstore created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a5ce37",
      "metadata": {
        "id": "d2a5ce37"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# 4Ô∏è‚É£ Improved Retriever Settings\n",
        "# -------------------------------------------------------------\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\n",
        "        \"k\": 5,\n",
        "        \"fetch_k\": 10,\n",
        "        \"lambda_mult\": 0.8\n",
        "    }\n",
        ")\n",
        "print(\"‚úÖ Retriever configured successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67d0019",
      "metadata": {
        "id": "e67d0019"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# 5Ô∏è‚É£ Create RAG QA System\n",
        "# -------------------------------------------------------------\n",
        "llm = OpenAI(temperature=0)\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "print(\"‚úÖ Retrieval-Augmented Generation (RAG) chain initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50d60523",
      "metadata": {
        "id": "50d60523"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# 6Ô∏è‚É£ Test Questions\n",
        "# -------------------------------------------------------------\n",
        "test_questions = [\n",
        "    \"Which diseases have the highest AI diagnostic accuracy?\",\n",
        "    \"How does AI help identify lung-related diseases?\",\n",
        "    \"What are the common symptoms among patients with high AI accuracy?\",\n",
        "    \"Which diagnosis has the lowest accuracy score?\"\n",
        "]\n",
        "\n",
        "print(\"\\nüîç Testing the RAG System on the Excel dataset:\\n\")\n",
        "for q in test_questions:\n",
        "    print(f\"üß© Question: {q}\")\n",
        "    print(\"üí° Answer:\", qa_chain.run(q))\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "print(\"‚úÖ RAG System Execution Complete ‚Äî Using Excel Dataset: AI in Healthcare\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}